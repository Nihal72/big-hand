{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this notebook we are taking the prepared data from previous version and for model building we willstack different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score , f1_score , precision_score , recall_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"../Data/PreparedData/train.csv\")\n",
    "test = pd.read_csv(r\"../Data/PreparedData/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"Survived\" , axis = 1).values\n",
    "y = train[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_org , x_test_org, y_train_org  , y_test_org = train_test_split(X , y , test_size = 0.3 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_org = x_train_org.shape[0]\n",
    "n_test_org = x_test_org.shape[0]\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=NFOLDS , shuffle = False , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelper(object):\n",
    "    def __init__(self , clf , seed =0, params = {}):\n",
    "        params[\"random_state\"] = seed\n",
    "        self.clf = clf(**params)\n",
    "        \n",
    "        \n",
    "    def fit(self , x_train ,y_train):\n",
    "        return self.clf.fit(x_train , y_train)\n",
    "    \n",
    "    def Predict(self, x_test , y_test):\n",
    "        return self.clf.predict(x_test )\n",
    "    \n",
    "    def FeatureImportance(self ,x_train , y_train):\n",
    "        return self.clf.fit(x_train , y_train).feature_importances\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_generator(clf, x_train_org , y_train_org , x_test_org):\n",
    "\n",
    "    oob_train = np.zeros((n_train_org, ))\n",
    "    oob_test_fld = np.zeros((n_test_org , NFOLDS))\n",
    "    oob_test = np.zeros((n_test_org , ))\n",
    "\n",
    "    for i ,(train_i ,test_i) in enumerate(kf.split(x_train_org)):\n",
    "        x_train, y_train = x_train_org[train_i] , y_train_org[train_i]\n",
    "        x_test , y_test = x_train_org[test_i] , y_train_org[test_i]\n",
    "\n",
    "        clf.fit(x_train , y_train)\n",
    "\n",
    "        oob_train[test_i] = Dtree.predict(x_test)\n",
    "        oob_test_fld[: , i] = Dtree.predict(x_test_org)\n",
    "\n",
    "    oob_test = oob_test_fld.mean(axis = 1)\n",
    "\n",
    "    return oob_train , oob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = oob_generator(et, x_train_org, y_train_org, x_test_org) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = oob_generator(rf,x_train_org, y_train_org, x_test_org) # Random Forest\n",
    "ada_oof_train, ada_oof_test = oob_generator(ada, x_train_org, y_train_org, x_test_org) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = oob_generator(gb,x_train_org, y_train_org, x_test_org) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = oob_generator(svc,x_train_org, y_train_org, x_test_org) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "IInd_train = pd.DataFrame({\"RF\":rf_oof_train , \"et\" : et_oof_train , \"ada\" : ada_oof_train , \"gb\" : gb_oof_train , \"svc\" : svc_oof_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "IInd_test = pd.DataFrame({\"RF\":rf_oof_test , \"et\" : et_oof_test , \"ada\" : ada_oof_test , \"gb\" : gb_oof_test , \"svc\" : svc_oof_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>et</th>\n",
       "      <th>ada</th>\n",
       "      <th>gb</th>\n",
       "      <th>svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RF   et  ada   gb  svc\n",
       "0    1.0  1.0  1.0  1.0  1.0\n",
       "1    0.0  0.0  0.0  0.0  0.0\n",
       "2    1.0  1.0  1.0  1.0  1.0\n",
       "3    0.0  0.0  0.0  0.0  0.0\n",
       "4    0.0  0.0  0.0  0.0  0.0\n",
       "..   ...  ...  ...  ...  ...\n",
       "618  0.0  0.0  0.0  0.0  0.0\n",
       "619  0.0  0.0  0.0  0.0  0.0\n",
       "620  0.0  0.0  0.0  0.0  0.0\n",
       "621  0.0  0.0  0.0  0.0  0.0\n",
       "622  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[623 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IInd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.9, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2000, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(IInd_train , y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723880597014925"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_org , gbm.predict(IInd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6995073891625616"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_org , gbm.predict(IInd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7717391304347826"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_org , gbm.predict(IInd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396396396396397"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test_org , gbm.predict(IInd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_org , x_test_org, y_train_org  , y_test_org = train_test_split(X , y , test_size = 0.3 , random_state = 42)\n",
    "\n",
    "train = pd.read_csv(r\"../Data/PreparedData/train.csv\")\n",
    "test = pd.read_csv(r\"../Data/PreparedData/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_org = train.drop(\"Survived\" , axis = 1).values\n",
    "y_train_org = train[\"Survived\"].values\n",
    "x_test_org = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_org = x_train_org.shape[0]\n",
    "n_test_org = x_test_org.shape[0]\n",
    "NFOLDS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=NFOLDS , shuffle = False , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelper(object):\n",
    "    def __init__(self , clf , seed =0, params = {}):\n",
    "        params[\"random_state\"] = seed\n",
    "        self.clf = clf(**params)\n",
    "        \n",
    "        \n",
    "    def fit(self , x_train ,y_train):\n",
    "        return self.clf.fit(x_train , y_train)\n",
    "    \n",
    "    def Predict(self, x_test , y_test):\n",
    "        return self.clf.predict(x_test )\n",
    "    \n",
    "    def FeatureImportance(self ,x_train , y_train):\n",
    "        return self.clf.fit(x_train , y_train).feature_importances\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_org = x_train_org.shape[0]\n",
    "n_test_org = x_test_org.shape[0]\n",
    "NFOLDS = 4\n",
    "\n",
    "def oob_generator(clf, x_train_org , y_train_org , x_test_org):\n",
    "\n",
    "    oob_train = np.zeros((n_train_org, ))\n",
    "    oob_test_fld = np.zeros((n_test_org , NFOLDS))\n",
    "    oob_test = np.zeros((n_test_org , ))\n",
    "\n",
    "    for i ,(train_i ,test_i) in enumerate(kf.split(x_train_org)):\n",
    "#         print(\"train_i->\" , train_i)\n",
    "#         print(\"test_i->\" , test_i)\n",
    "        \n",
    "        x_train, y_train = x_train_org[train_i] , y_train_org[train_i]\n",
    "        x_test , y_test = x_train_org[test_i] , y_train_org[test_i]\n",
    "\n",
    "        clf.fit(x_train , y_train)\n",
    "\n",
    "        oob_train[test_i] = Dtree.predict(x_test)\n",
    "        oob_test_fld[: , i] = Dtree.predict(x_test_org)\n",
    "\n",
    "    oob_test = oob_test_fld.mean(axis = 1)\n",
    "\n",
    "    return oob_train , oob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = oob_generator(et, x_train_org, y_train_org, x_test_org) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = oob_generator(rf,x_train_org, y_train_org, x_test_org) # Random Forest\n",
    "ada_oof_train, ada_oof_test = oob_generator(ada, x_train_org, y_train_org, x_test_org) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = oob_generator(gb,x_train_org, y_train_org, x_test_org) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = oob_generator(svc,x_train_org, y_train_org, x_test_org) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "IInd_train = pd.DataFrame({\"RF\":rf_oof_train , \"et\" : et_oof_train , \"ada\" : ada_oof_train , \"gb\" : gb_oof_train , \"svc\" : svc_oof_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "IInd_test = pd.DataFrame({\"RF\":rf_oof_test , \"et\" : et_oof_test , \"ada\" : ada_oof_test , \"gb\" : gb_oof_test , \"svc\" : svc_oof_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>et</th>\n",
       "      <th>ada</th>\n",
       "      <th>gb</th>\n",
       "      <th>svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RF   et  ada   gb  svc\n",
       "0    0.0  0.0  0.0  0.0  0.0\n",
       "1    1.0  1.0  1.0  1.0  1.0\n",
       "2    0.0  0.0  0.0  0.0  0.0\n",
       "3    1.0  1.0  1.0  1.0  1.0\n",
       "4    0.0  0.0  0.0  0.0  0.0\n",
       "..   ...  ...  ...  ...  ...\n",
       "886  0.0  0.0  0.0  0.0  0.0\n",
       "887  1.0  1.0  1.0  1.0  1.0\n",
       "888  0.0  0.0  0.0  0.0  0.0\n",
       "889  0.0  0.0  0.0  0.0  0.0\n",
       "890  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IInd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.9, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2000, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(IInd_train , y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =  gbm.predict(IInd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(r\"../Data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived'], dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitDF = pd.DataFrame({\"PassengerId\" : subm[\"PassengerId\"] , \"Survived\" : pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitDF.to_csv(r\"../Data/Predictions/TunedStackXG.csv\" , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
